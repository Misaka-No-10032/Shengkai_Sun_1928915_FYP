{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy import uint8\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from scipy.io import loadmat\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from sklearn.metrics import precision_score, f1_score\n",
    "from cluster import RLOMTFAGCluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 30\n",
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('./data/UMIST.mat')\n",
    "X = data['fea'].astype(uint8)\n",
    "y = data['gnd'].reshape(-1).astype(uint8) - 1\n",
    "X_ = X.T.reshape(-1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE_Block(nn.Module):\n",
    "    def __init__(self, c, r=16):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(c, c // r, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(c // r, c, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, c, _, _ = x.shape\n",
    "        y = self.squeeze(x).view(bs, c)\n",
    "        y = self.excitation(y).view(bs, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SENet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), nn.ReLU(),  # 32, 32, 32\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 32, 16, 16\n",
    "            nn.Conv2d(6, 16, kernel_size=5), nn.ReLU(),  # 64, 12, 12\n",
    "            SE_Block(c=16, r=4),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 64, 6, 6\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 120), nn.ReLU(),\n",
    "            nn.Linear(120, 84), nn.ReLU(),\n",
    "            nn.Linear(84, 20)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UMISTDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = UMISTDataset(X_train, y_train, transform=train_transform)\n",
    "test_dataset = UMISTDataset(X_test, y_test, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the RGB images to an nd-array,\n",
    "# the values are the gray scale,\n",
    "# each column is an image\n",
    "SEED = 42\n",
    "# def convert_to_ndarray(loader):\n",
    "#     images = []\n",
    "#     torch.manual_seed(SEED)\n",
    "#     for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "#         for i in range(len(targets)):\n",
    "#             img = inputs[i]\n",
    "#             img = img * 0.5 + 0.5\n",
    "#             img = img.numpy()\n",
    "#             img = np.transpose(img, (1, 2, 0))\n",
    "#             img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#             images.append(img.flatten())\n",
    "#     images = np.array(images).T\n",
    "#     return images\n",
    "\n",
    "# # target_images = convert_to_ndarray(targetloader)\n",
    "# train_images = convert_to_ndarray(train_loader)\n",
    "\n",
    "target_images = X[:, 0:256]\n",
    "param = [1e-9, 1e-3, 1e-2, 7, 27]\n",
    "# data = loadmat('/output/data/UMIST.mat')\n",
    "# X = data['fea'].astype(np.float64)\n",
    "# y = data['gnd'].astype(int)\n",
    "payload = {'X': target_images,\n",
    "           'k': 20,\n",
    "           'param': param,\n",
    "           'limiter': 100,\n",
    "           'epsilon': 1e-10,\n",
    "           'distance_metric': 'sqeuclidean'}\n",
    "\n",
    "rlomtfag_cls = RLOMTFAGCluster()\n",
    "rlomtfag_cls.fit(payload)\n",
    "\n",
    "\n",
    "class EnhancedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 20)\n",
    "        self.se = SE_Block(c=16, r=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        X = []\n",
    "        for i in range(len(x)):\n",
    "            img = x[i]\n",
    "            img = img.detach().cpu().numpy()\n",
    "            X.append(img.flatten())\n",
    "        X = np.array(X).T\n",
    "        cls_fea = rlomtfag_cls.project(X).T\n",
    "        cls_fea = torch.from_numpy(cls_fea).float()\n",
    "        cls_fea = cls_fea.to(device)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(self.se(F.relu(self.conv2(x))))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        cls_fea = torch.sigmoid(cls_fea)\n",
    "        x = torch.add(x, cls_fea)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = EnhancedNet().to(device)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_num, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device).long()\n",
    "        # 将梯度初始化为0，pytorch中的梯度会自动累加，因此每次都要初始化\n",
    "        optimizer.zero_grad()\n",
    "        result = model(data)\n",
    "        # 计算损失\n",
    "        loss = F.cross_entropy(result, label)\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Update 参数\n",
    "        optimizer.step()\n",
    "        if (batch_num + 1) % 3 == 0:\n",
    "            print(\n",
    "                f'Epoch: {epoch}\\tBatch: {batch_num + 1}\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "\n",
    "def test_model(model, device, test_loader):\n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    # loss\n",
    "    test_loss = 0.0\n",
    "    pred_all = []\n",
    "    label_all = []\n",
    "    labels = list(range(20))\n",
    "    n_classes = 4\n",
    "    # 测试过程不需要计算梯度和反向传播\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            label_all.extend(label)\n",
    "            data, label = data.to(device), label.to(device).long()\n",
    "            result = model(data)\n",
    "            # 计算test损失\n",
    "            test_loss += F.cross_entropy(result, label).item()\n",
    "            # 找到最大值下标\n",
    "            pred = result.argmax(dim=1)\n",
    "            pred_all.extend(pred.cpu().data.numpy())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    confmat = confusion_matrix(torch.tensor(label_all), torch.tensor(pred_all))\n",
    "    print(f'{confmat}')\n",
    "\n",
    "    pred_all = label_binarize(pred_all, classes=labels)\n",
    "    label_all = label_binarize(label_all, classes=labels)\n",
    "    precision = precision_score(label_all, pred_all, average='macro')\n",
    "    recall = recall_score(label_all, pred_all, average='macro')\n",
    "    f1 = f1_score(label_all, pred_all, average='macro')\n",
    "    acc = accuracy_score(label_all, pred_all)\n",
    "\n",
    "    print(\"\\nPrecision Score: \", precision)\n",
    "    print(\"Recall Score: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"Accuracy Score: \", acc)\n",
    "    print(f'\\nTest Average Loss: {test_loss:.6f}')\n",
    "    print(\n",
    "        f\"\\nAUC: {roc_auc_score(label_all, pred_all, average='macro', multi_class='ovo', labels=labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 30 + 1):\n",
    "    train_model(net, device, train_loader, optimizer, epoch)\n",
    "    test_model(net, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
