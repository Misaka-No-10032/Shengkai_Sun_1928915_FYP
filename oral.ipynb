{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from cluster import RLOMTFAGCluster\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from sklearn.metrics import precision_score, f1_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 30\n",
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SE_Block(nn.Module):\n",
    "    def __init__(self, c, r=16):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(c, c // r, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(c // r, c, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, c, _, _ = x.shape\n",
    "        y = self.squeeze(x).view(bs, c)\n",
    "        y = self.excitation(y).view(bs, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3,\n",
    "                      padding=2), nn.ReLU(),  # 32, 32, 32\n",
    "            SE_Block(c=32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 32, 16, 16\n",
    "            nn.Conv2d(32, 64, kernel_size=5), nn.ReLU(),  # 64, 12, 12\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 64, 6, 6\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 6 * 6, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        # y = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_num, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        # 将梯度初始化为0，pytorch中的梯度会自动累加，因此每次都要初始化\n",
    "        optimizer.zero_grad()\n",
    "        result = model(data)\n",
    "        # 计算损失\n",
    "        loss = F.cross_entropy(result, label)\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Update 参数\n",
    "        optimizer.step()\n",
    "        if (batch_num + 1) % 3 == 0:\n",
    "            print(\n",
    "                f'Epoch: {epoch}\\tBatch: {batch_num + 1}\\tLoss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, device, test_loader):\n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    # loss\n",
    "    test_loss = 0.0\n",
    "    pred_all = []\n",
    "    label_all = []\n",
    "    labels = [0, 1, 2, 3]\n",
    "    n_classes = 4\n",
    "    # 测试过程不需要计算梯度和反向传播\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            label_all.extend(label)\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            result = model(data)\n",
    "            # 计算test损失\n",
    "            test_loss += F.cross_entropy(result, label).item()\n",
    "            # 找到最大值下标\n",
    "            pred = result.argmax(dim=1)\n",
    "            pred_all.extend(pred.cpu().data.numpy())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    confmat = confusion_matrix(torch.tensor(label_all), torch.tensor(pred_all))\n",
    "    print(f'{confmat}')\n",
    "\n",
    "    pred_all = label_binarize(pred_all, classes=labels)\n",
    "    label_all = label_binarize(label_all, classes=labels)\n",
    "    precision = precision_score(label_all, pred_all, average='macro')\n",
    "    recall = recall_score(label_all, pred_all, average='macro')\n",
    "    f1 = f1_score(label_all, pred_all, average='macro')\n",
    "    acc = accuracy_score(label_all, pred_all)\n",
    "\n",
    "    print(\"\\nPrecision Score: \", precision)\n",
    "    print(\"Recall Score: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"Accuracy Score: \", acc)\n",
    "    print(f'\\nTest Average Loss: {test_loss:.6f}')\n",
    "    print(\n",
    "        f\"\\nAUC: {roc_auc_score(label_all, pred_all, average='macro', multi_class='ovo', labels=labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image training dataset in ./data/oral/full/train the folder name is the label\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "aug_train_dataset = torchvision.datasets.ImageFolder(\n",
    "    './data/oral/full/train_augmented', transform=train_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    aug_train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Load image testing dataset in ./data/oral/full/test the folder name is the label\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "aug_test_dataset = torchvision.datasets.ImageFolder(\n",
    "    './data/oral/full/test_augmented', transform=test_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    aug_test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the RGB images to an nd-array,\n",
    "# the values are the gray scale,\n",
    "# each column is an image\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "def convert_to_ndarray(loader):\n",
    "    images = []\n",
    "    torch.manual_seed(SEED)\n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        for i in range(len(targets)):\n",
    "            img = inputs[i]\n",
    "            # unnormalize\n",
    "            img = img * torch.tensor(std).view(3, 1, 1) + \\\n",
    "                torch.tensor(mean).view(3, 1, 1)\n",
    "            img = img.numpy()\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            images.append(img.flatten())\n",
    "    images = np.array(images).T\n",
    "    return images\n",
    "\n",
    "\n",
    "# target_images = convert_to_ndarray(targetloader)\n",
    "train_images = convert_to_ndarray(train_loader)\n",
    "# test_images = convert_to_ndarray(testloader)\n",
    "\n",
    "# train_images.shape\n",
    "\n",
    "target_images = train_images[:, 0:256]\n",
    "param = [1e-7, 1e-4, 1e-5, 3, 4]\n",
    "# data = loadmat('/output/data/UMIST.mat')\n",
    "# X = data['fea'].astype(np.float64)\n",
    "# y = data['gnd'].astype(int)\n",
    "payload = {'X': target_images,\n",
    "           'k': 4,\n",
    "           'param': param,\n",
    "           'limiter': 100,\n",
    "           'epsilon': 1e-10,\n",
    "           'distance_metric': 'sqeuclidean'}\n",
    "\n",
    "rlomtfag_cls = RLOMTFAGCluster()\n",
    "rlomtfag_cls.fit(payload)\n",
    "\n",
    "# CNN_net = CNN().to(device)\n",
    "\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = optim.Adam(CNN_net.parameters(), lr)  # update parameter\n",
    "# optimizer = optim.SGD(CNN_net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3,\n",
    "                      padding=2), nn.ReLU(),  # 32, 32, 32\n",
    "            SE_Block(c=32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 32, 16, 16\n",
    "            nn.Conv2d(32, 64, kernel_size=5), nn.ReLU(),  # 64, 12, 12\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 64, 6, 6\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 6 * 6, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        X = []\n",
    "        for i in range(len(x)):\n",
    "            img = x[i]\n",
    "            img = img * 0.5 + 0.5\n",
    "            img = img.detach().cpu().numpy()\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            X.append(img.flatten())\n",
    "        X = np.array(X).T\n",
    "        cls_fea = rlomtfag_cls.project(X).T\n",
    "        cls_fea = torch.from_numpy(cls_fea).float()\n",
    "        cls_fea = cls_fea.to(device)\n",
    "        x = self.net(x)\n",
    "        cls_fea = torch.sigmoid(cls_fea)\n",
    "        x = torch.add(x, cls_fea)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "net = EnhancedNet().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train_model(net, device, train_loader, optimizer, epoch)\n",
    "    test_model(net, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "35fd8a9ef6fc8792bce29f3f397e2590ca2dbc3d38d59c98418e6afec6480810"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
